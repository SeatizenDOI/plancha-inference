{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0de7029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import traceback\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from torchvision import transforms\n",
    "from huggingface_hub import hf_hub_download\n",
    "from open_clip import create_model, get_tokenizer\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "RANKS = [\"kingdom\", \"phylum\", \"class\", \"order\", \"family\", \"genus\", \"species\"]\n",
    "ranks = [a.title() for a in RANKS]\n",
    "\n",
    "MODEL_STR = \"hf-hub:imageomics/bioclip-2\"\n",
    "TOKENIZER_STR = \"ViT-L-14\"\n",
    "HF_DATA_STR = \"imageomics/TreeOfLife-200M\"\n",
    "NB_CLASS_TO_KEEP = 5\n",
    "\n",
    "SESSION_PATH = Path(\"/media/bioeos/F/202505_plancha_session/20250519_REU-ST-LEU_ASV-1_01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25f21d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BioClip2:\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.preprocess_img = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Resize((224, 224), antialias=True),\n",
    "                transforms.Normalize(\n",
    "                    mean=(0.48145466, 0.4578275, 0.40821073),\n",
    "                    std=(0.26862954, 0.26130258, 0.27577711),\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.init_model()\n",
    "    \n",
    "    def init_model(self):\n",
    "        self.model = create_model(MODEL_STR, output_dict=True, require_pretrained=True)\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "        self.tokenizer = get_tokenizer(TOKENIZER_STR)\n",
    "\n",
    "        self.txt_emb = torch.from_numpy(np.load(hf_hub_download(\n",
    "            repo_id=HF_DATA_STR,\n",
    "            filename=\"embeddings/txt_emb_species.npy\",\n",
    "            repo_type=\"dataset\",\n",
    "        ))).to(self.device)\n",
    "        \n",
    "        with open(hf_hub_download(\n",
    "            repo_id=HF_DATA_STR,\n",
    "            filename=\"embeddings/txt_emb_species.json\",\n",
    "            repo_type=\"dataset\",\n",
    "        )) as fd:\n",
    "            self.txt_names = json.load(fd)\n",
    "        \n",
    "        with open(hf_hub_download(\n",
    "                repo_id=\"imageomics/bioclip-2-demo\",\n",
    "                filename=\"components/metadata.parquet\",\n",
    "                repo_type=\"space\",\n",
    "            )) as fd:\n",
    "\n",
    "                self.metadata_df = pl.read_parquet(fd, low_memory = False)\n",
    "                self.metadata_df = self.metadata_df.with_columns(pl.col([\"eol_page_id\", \"gbif_id\"]).cast(pl.Int64))\n",
    "\n",
    "    def format_name(self, taxon, common):\n",
    "        taxon = \" \".join(taxon)\n",
    "        if not common:\n",
    "            return taxon\n",
    "        return f\"{taxon} ({common})\"\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict(self, img):\n",
    "   \n",
    "        img = self.preprocess_img(img).to(self.device)\n",
    "        img_features = self.model.encode_image(img.unsqueeze(0))\n",
    "        img_features = F.normalize(img_features, dim=-1)\n",
    "\n",
    "        logits = (self.model.logit_scale.exp() * img_features @ self.txt_emb).squeeze()\n",
    "        probs = F.softmax(logits, dim=0).to(\"cpu\")\n",
    "        topk = probs.topk(NB_CLASS_TO_KEEP)\n",
    "        prediction_dict = {\n",
    "            self.format_name(*self.txt_names[i]): prob for i, prob in zip(topk.indices, topk.values)\n",
    "        }\n",
    "\n",
    "        return prediction_dict\n",
    "\n",
    "    def get_sample_data(self, pred_taxon, rank = 6):\n",
    "        for idx in range(rank + 1):\n",
    "            taxon = RANKS[idx]\n",
    "            target_taxon = pred_taxon.split(\" \")[idx]\n",
    "            self.metadata_df = self.metadata_df.filter(pl.col(taxon) == target_taxon)\n",
    "\n",
    "        if self.metadata_df.shape[0] == 0:\n",
    "            return None, np.nan, np.nan, \"\", False\n",
    "\n",
    "        # First, try to find entries with empty lower ranks\n",
    "        exact_df = self.metadata_df\n",
    "        for lower_rank in RANKS[rank + 1:]:\n",
    "            exact_df = exact_df.filter((pl.col(lower_rank).is_null()) | (pl.col(lower_rank) == \"\"))\n",
    "\n",
    "        if exact_df.shape[0] > 0:\n",
    "            df_filtered = exact_df.sample()\n",
    "            full_name = \" \".join(df_filtered.select(RANKS[:rank+1]).row(0))\n",
    "            return df_filtered[\"file_path\"][0], df_filtered[\"gbif_taxon_id\"].cast(pl.String)[0], df_filtered[\"eol_page_id\"].cast(pl.String)[0], full_name, True\n",
    "\n",
    "        # If no exact matches, return any entry with the specified rank\n",
    "        df_filtered = self.metadata_df.sample()\n",
    "        full_name = \" \".join(df_filtered.select(RANKS[:rank+1]).row(0)) + \" \" + \" \".join(df_filtered.select(RANKS[rank+1:]).row(0))\n",
    "        return df_filtered[\"file_path\"][0], df_filtered[\"gbif_taxon_id\"].cast(pl.String)[0], df_filtered[\"eol_page_id\"].cast(pl.String)[0], full_name, False\n",
    "\n",
    "\n",
    "bioclip = BioClip2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e73296",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not SESSION_PATH.exists(): raise NameError(\"Session not found\")\n",
    "\n",
    "metadata_csv_path = Path(SESSION_PATH, \"METADATA\", \"metadata.csv\")\n",
    "if not metadata_csv_path.exists(): raise NameError(\"Metadata csv not found\")\n",
    "\n",
    "frame_path = Path(SESSION_PATH, \"PROCESSED_DATA/FRAMES\")\n",
    "ia_path = Path(SESSION_PATH, \"PROCESSED_DATA/IA\")\n",
    "ia_path.mkdir(exist_ok=True)\n",
    "\n",
    "csv_connector_classes = open(Path(ia_path, \"bioclip2.csv\"), \"w\")\n",
    "csv_connector_classes.write(f\"FileName,{','.join(ranks)},score,gbif_id,eol_id\\n\")\n",
    "\n",
    "try:\n",
    "    for img_path in tqdm(sorted(list(Path(frame_path).iterdir()))):\n",
    "        img_input = Image.open(img_path)\n",
    "        open_domain_output = bioclip.predict(img_input)\n",
    "\n",
    "        key_with_max_value = max(open_domain_output, key=lambda k: open_domain_output[k])\n",
    "        _, gbif_id, eol_id, _, _ = bioclip.get_sample_data(key_with_max_value)\n",
    "        csv_connector_classes.write(f\"{img_path.name},{key_with_max_value.split(' (')[0].replace(' ', ',')},{open_domain_output[key_with_max_value]},{gbif_id},{eol_id}\\n\")\n",
    "\n",
    "except:\n",
    "    print(traceback.format_exc(), end=\"\\n\\n\")\n",
    "finally:\n",
    "    csv_connector_classes.close()\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inference_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
